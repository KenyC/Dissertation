{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Chapter 1\n",
        "====================================\n",
        "In this computation, I use \"a or b\" as a proxy for an existential with sub-domain alternatives.\n",
        "\n",
        "Some global preliminaries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Imports \n",
        "from exh           import *\n",
        "from exh.exts.gq   import *\n",
        "from exh.model     import options\n",
        "import exh.options as     options_alts\n",
        "\n",
        "options.dom_quant     = 4      # Setting a large-ish domain of quantification\n",
        "options.latex_display = False  # disabling LateX display ; you can enable if you're using Jupyter Notebook (as opposed to IPython) \n",
        "display = jprint if options.latex_display else print\n",
        "options_alts.scales   = [{Existential, Universal}, {Existential, Most}] # Remove \"or\"/\"and\" scale; we'll be using disjunction to model existentials without universal alternatives\n",
        "\n",
        "# setting a and b to depend on x (innocuous warnings appear)\n",
        "# here, we only use thee disjuncts ; the number of logical possibility can quickly explode\n",
        "a(\"x\")\n",
        "b(\"x\")\n",
        "c(\"x\")\n",
        "\n",
        "# Match names in text\n",
        "Anut  = A(\"nut\")\n",
        "Enut  = E(\"nut\")\n",
        "scrat = Pred(4, name = \"scrat\", depends = \"nut\")\n",
        "acorn = Pred(5, name = \"acorn\", depends = \"nut\")\n",
        "waggs = Pred(6, name = \"waggs\", depends = \"nut\")\n",
        "\n",
        "Aamb  = A(\"amb\")\n",
        "Eamb  = E(\"amb\")\n",
        "arabic   = Pred(4, name = \"arabic\",   depends = \"amb\")\n",
        "english  = Pred(5, name = \"english\",  depends = \"amb\")\n",
        "mandarin = Pred(6, name = \"mandarin\", depends = \"amb\")\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span id=\"noncumulative\"></span>\n",
        "# Exhaustive participation inferences in non-cumulative sentences: recursive Exh \n",
        "*The dancers smiled*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Here, we model the dancers as a grand disjunction\n",
        "marielou = Pred(5, name = \"marielou\")\n",
        "pierre   = Pred(6, name = \"pierre\")\n",
        "rebecca  = Pred(7, name = \"rebecca\")\n",
        "wilfried = Pred(8, name = \"wilfried\")\n",
        "nazli    = Pred(9, name = \"nazli\")\n",
        "# dancers  = [marielou, pierre, rebecca, wilfried, nazli]\n",
        "\n",
        "prejacent = marielou | pierre | rebecca | wilfried | nazli\n",
        "universe = Universe(f = prejacent) # Universe objects contain all logical possibilities ; we can use them to check for equivalences\n",
        "sentence  = Exh(Exh(prejacent))\n",
        "print(\"Assumed sentence:\", sentence)\n",
        "print(\n",
        "\t\"Equivalent to universal/grand conjunction:\", \n",
        "\tuniverse.equivalent(sentence, marielou & pierre & rebecca & wilfried & nazli)\n",
        ")\n",
        "# Printing excluded alternatives\n",
        "sentence.diagnose(display)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span id=\"noncumulative_ii\"></span>\n",
        "# Exhaustive participation inferences in non-cumulative sentences: innocent inclusion Exh \n",
        "*The dancers smiled*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "prejacent = marielou | pierre | rebecca | wilfried | nazli\n",
        "universe = Universe(f = prejacent) # Universe objects contain all logical possibilities ; we can use them to check for equivalences\n",
        "sentence  = Exh(prejacent, ii = True)\n",
        "print(\"Assumed sentence:\", sentence)\n",
        "print(\n",
        "\t\"Equivalent to universal/grand conjunction:\", \n",
        "\tuniverse.equivalent(sentence, marielou & pierre & rebecca & wilfried & nazli)\n",
        ")\n",
        "# Printing excluded alternatives\n",
        "sentence.diagnose(display)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span id=\"cumulative_every_naive\"></span>\n",
        "# Cumulative reading of every/distributive implicatures : non-recursive exhaustification\n",
        "*Every ambassador speaks Arabic, French or Mandarin*  \n",
        "*The three squirrels cracked every nut*\n",
        "\n",
        "Note how we perform the exhaustification, ignoring that \"every\" has \"some\" as an alternative. As pointed out by Chemla & Spector (2011), the \"some\" alternative block the distributive implicature, a testament to the inadequacy of the standard derivation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "prejacent  = Anut > scrat | acorn | waggs\n",
        "universe   = Universe(f = prejacent)\n",
        "sentence   = Exh(prejacent, scales = []) # we must ignore the \"some/all\" scales. As p\n",
        "\n",
        "print(\"Assumed LF:\", sentence)\n",
        "\n",
        "sentence.diagnose(display)\n",
        "print(\n",
        "\t\"There is a nut that only Scrat cracked:\", \n",
        "\tuniverse.entails(sentence, Enut > scrat & ~acorn & ~waggs)\n",
        ")\n",
        "print(\n",
        "\t\"Equivalent to true cumulative reading:\", \n",
        "\tuniverse.equivalent(\n",
        "\t\tsentence, \n",
        "\t\tprejacent & (Enut > scrat) & (Enut > acorn) & (Enut > waggs)\n",
        "\t)\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span id=\"dist_ii\"></span>\n",
        "# Distributive implicature/cumulative readings of \"every\" : innocent exclusion exhaustification\n",
        "*Every ambassador speaks Arabic, French or Mandarin*  \n",
        "*The three squirrels cracked every nut*\n",
        "\n",
        "Note how we perform the exhaustification, ignoring that \"every\" has \"some\" as an alternative. As pointed out by Chemla & Spector (2011), the \"some\" alternative block the distributive implicature, a testament to the inadequacy of the standard derivation.\n",
        "Because II exhaustification embeds IE exhaustification, the results are the same.\n",
        "\"\"\"\n",
        "\n",
        "prejacent  = Ax > a | b | c\n",
        "universe   = Universe(f = prejacent)\n",
        "sentence   = Exh(prejacent, scales = [], ii = True) # here too, we must ignore the \"some/all\" scales. As p\n",
        "\n",
        "print(\"Assumed LF:\", sentence)\n",
        "\n",
        "# Since exclusion happens first, the derived result is the same as above\n",
        "sentence.diagnose(display)\n",
        "print(\n",
        "\t\"There is a nut that only Scrat cracked:\", \n",
        "\tuniverse.entails(sentence, Ex > a & ~b & ~c)\n",
        ")\n",
        "\n",
        "dist = (Ex > a) & (Ex > b) & (Ex > c)\n",
        "print(\"Equivalent to prejacent + dist implicatures (i.e. {}):\".format(dist))\n",
        "print(\n",
        "\tuniverse.equivalent(\n",
        "\t\tsentence, \n",
        "\t\tprejacent & dist\n",
        "\t)\n",
        ")\n",
        "print()\n",
        "\n",
        "# %% \n",
        "\"\"\"\n",
        "What if we allowed the \"some\" alternative to \"all\"? The reading is equivalent to the following conjuntive statement:  \n",
        "*Every ambassador speaks Arabic, English and Mandarin.*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sentence = Exh(prejacent, \n",
        "               scales = [{Existential, Universal}],\n",
        "               ii     = True)\n",
        "sentence.diagnose(display) \n",
        "# The reading is way too strong!\n",
        "print(\n",
        "\t\"Equivalent to doubly distributive reading:\", \n",
        "\tuniverse.equivalent(\n",
        "\t\tsentence, \n",
        "\t\tAx > a & b & c\n",
        "\t)\n",
        ")\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span id=\"dist_ii_conj\"></span>\n",
        "What if we allowed both \"some/all\" and \"or/and\"?\n",
        "Here, we generated an embedded implicature that \"every ambassador speaks only one of the three languages\" and no distributive implicature.\n",
        "Note that pruning alternatives here (if we follow Bar-Lev (2018)) since pruning in his system only makes statements weaker.\n",
        "Since the fully exhuastified statement does not entail the dist. implicature, the pruned statement won't either.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sentence = Exh(prejacent, \n",
        "               scales = [{Existential, Universal},  {Or, And}],\n",
        "               ii     = True)\n",
        "sentence.diagnose(display) \n",
        "# The reading has an embedded implicature\n",
        "print(\n",
        "\t\"Equivalent to embeded implicature:\", \n",
        "\tuniverse.equivalent(\n",
        "\t\tsentence, \n",
        "\t\tAx > (a & ~b & ~c) | (~a & b & ~c) | (~a & ~b & c)\n",
        "\t)\n",
        ")\n",
        "\n",
        "print(\n",
        "\t\"Has distributive implicature:\", \n",
        "\tuniverse.equivalent(\n",
        "\t\tsentence, \n",
        "\t\tEx > a\n",
        "\t)\n",
        ")\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span id=\"dist_recursive\"></span>\n",
        "# Distributive implicatures with recursive exhaustification \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "prejacent  = Ax > a | b | c\n",
        "universe = Universe(f = prejacent)\n",
        "sentence   = Exh(Exh(prejacent, subst = True), subst = True)\n",
        "\n",
        "print(\"Assumed LF:\", sentence)\n",
        "\n",
        "sentence.diagnose(display)\n",
        "\n",
        "dist = (Ex > a) & (Ex > b) & (Ex > c)\n",
        "print(\"Target Distributive Implicatures:\", dist)\n",
        "print(\n",
        "\t\"Equivalent to conjunction of prejacent and dist implicature:\", \n",
        "\tuniverse.equivalent(\n",
        "\t\tsentence, \n",
        "\t\tprejacent & dist\n",
        "\t)\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span id=\"cumulative_every\"></span>\n",
        "# Cumulative reading of every \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "prejacent  = Anut > scrat | acorn | waggs\n",
        "universe = Universe(f = prejacent)\n",
        "sentence   = Exh(Exh(prejacent))\n",
        "\n",
        "print(\"Assumed LF:\", sentence)\n",
        "\n",
        "sentence.diagnose(print)\n",
        "print(\n",
        "\t\"Equivalent to cumulative reading:\", \n",
        "\tuniverse.equivalent(\n",
        "\t\tsentence, \n",
        "\t\tprejacent & (Enut > scrat) & (Enut > acorn) & (Enut > waggs)\n",
        "\t)\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span id=\"cumulative_every_ii\"></span>\n",
        "# Cumulative reading of every: the innocent inclusion approach \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "prejacent  = Ax > a | b | c\n",
        "sentence   = Exh(prejacent, ii = True)\n",
        "universe = Universe(f = prejacent)\n",
        "\n",
        "print(\"Assumed LF:\", sentence)\n",
        "\n",
        "sentence.diagnose(display)\n",
        "print(\n",
        "\t\"Equivalent to cumulative reading:          \", \n",
        "\tuniverse.equivalent(\n",
        "\t\tsentence, \n",
        "\t\tprejacent & (Ex > a) & (Ex > b) & (Ex > c)\n",
        "\t)\n",
        ")\n",
        "print(\"Equivalent to doubly-distributive reading: \", universe.equivalent(sentence, (Ax > a) & (Ax > b) & (Ax > c)))\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span id=\"cumulative_most\"></span>\n",
        "# Cumulative reading of most \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "prejacent  = Mx > a | b | c\n",
        "first_exh  = Exh(prejacent)\n",
        "lf         = Exh(first_exh)\n",
        "\n",
        "print(\"Assumed LF:\", lf)\n",
        "\n",
        "lf.diagnose(display)\n",
        "print(\"Equivalent to cumulative reading:\", universe.equivalent(lf, prejacent & (Ex > a) & (Ex > b) & (Ex > c)))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span id=\"asymmetries\"></span>\n",
        "# Asymmetries in cumulative readings \n",
        "Non-cumulative reading of every.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "scales     = [{Existential, Universal}] # our \"disjunction\", which models the existential with subdomain alternates, should not have a conjunctive alternative\n",
        "lf         = Exh(Exh(Ax > Exh(Exh(a | b))))\n",
        "print(\"Assumed LF:\", lf)\n",
        "\n",
        "\n",
        "\n",
        "lf.diagnose(display)\n",
        "print(\"Equivalent to cumulative reading:\", universe.equivalent(lf, (Ax > a | b) & (Ex > a) & (Ex > b)))\n",
        "print(\"Equivalent to doubly-dist reading:\", universe.equivalent(lf, Ax > a & b))\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span id=\"asymmetries\"></span>\n",
        "# Asymmetries in cumulative readings \n",
        "Non-cumulative reading of every.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "scales     = [{Existential, Universal}] # our \"disjunction\", which models the existential with subdomain alternates, should not have a conjunctive alternative\n",
        "lf         = Exh(Exh(Ax > Exh(Exh(a | b))))\n",
        "print(\"Assumed LF:\", lf)\n",
        "\n",
        "\n",
        "\n",
        "lf.diagnose(display)\n",
        "print(\"Equivalent to cumulative reading:\", universe.equivalent(lf, (Ax > a | b) & (Ex > a) & (Ex > b)))\n",
        "print(\"Equivalent to doubly-dist reading:\", universe.equivalent(lf, Ax > a & b))\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span id=\"ordinary\"></span>\n",
        "# Ordinary cumulative sentences \n",
        "Ordinary cumulative sentences  \n",
        "*The squirrels cracked the nuts*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "s1_cracked_n1 = Pred(1, name = \"s1 cracked n1\")\n",
        "s1_cracked_n2 = Pred(2, name = \"s2 cracked n1\")\n",
        "s2_cracked_n1 = Pred(3, name = \"s1 cracked n2\")\n",
        "s2_cracked_n2 = Pred(4, name = \"s2 cracked n2\")\n",
        "\n",
        "\n",
        "sentence = Exh(Exh(s1_cracked_n1, alts = [s1_cracked_n2]))\n",
        "print(sentence.alts)\n",
        "# print(\"Equivalent to cumulative reading:\", universe.equivalent(lf, (Ax > a | b) & (Ex > a) & (Ex > b)))\n",
        "# print(\"Equivalent to doubly-dist reading:\", universe.equivalent(lf, Ax > a & b))\n",
        "\n",
        "\n",
        "# %%"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}